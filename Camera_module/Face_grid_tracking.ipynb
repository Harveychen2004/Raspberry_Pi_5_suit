{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a6edd7db3545e2ba98b2ca5b71546a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:17:28.840861281] [3612] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:284 \u001b[0mlibcamera v0.1.0+118-563cd78e\n",
      "[0:17:28.876641780] [3644] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:653 \u001b[0mlibpisp version v1.0.2 fa44a258644a 22-11-2023 (21:59:22)\n",
      "[0:17:28.886235571] [3644] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1112 \u001b[0mRegistered camera /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a to CFE device /dev/media2 and ISP device /dev/media0 using PiSP variant BCM2712_C0\n",
      "[0:17:28.889390423] [3612] \u001b[1;33m WARN \u001b[1;37mV4L2 \u001b[1;34mv4l2_pixelformat.cpp:338 \u001b[0mUnsupported V4L2 pixel format Y16 \n",
      "[0:17:28.889420481] [3612] \u001b[1;33m WARN \u001b[1;37mV4L2 \u001b[1;34mv4l2_pixelformat.cpp:338 \u001b[0mUnsupported V4L2 pixel format RGB6\n",
      "[0:17:28.889424982] [3612] \u001b[1;33m WARN \u001b[1;37mV4L2 \u001b[1;34mv4l2_pixelformat.cpp:338 \u001b[0mUnsupported V4L2 pixel format BGR6\n",
      "[0:17:28.889431019] [3612] \u001b[1;33m WARN \u001b[1;37mV4L2 \u001b[1;34mv4l2_pixelformat.cpp:338 \u001b[0mUnsupported V4L2 pixel format PC1M\n",
      "[0:17:28.890135001] [3612] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1183 \u001b[0mconfiguring streams: (0) 640x480-XRGB8888 (1) 1536x864-GRBG16_PISP_COMP1\n",
      "[0:17:28.890223492] [3644] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1396 \u001b[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 1536x864-SGRBG10_1X10 - Selected CFE format: 1536x864-PC1G\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1750400187.116763    3612 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blendshapes data saved to data/Camera.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from adafruit_servokit import ServoKit\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import libcamera\n",
    "from picamera2 import Picamera2\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "class DriverMonitor:\n",
    "    def __init__(self):\n",
    "        # UI Display Widget\n",
    "        self.face_image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "        display(self.face_image_widget)\n",
    "\n",
    "        # Servo setup\n",
    "        self.kit = ServoKit(channels=16)\n",
    "        self.pan = 90\n",
    "        self.tilt = 90\n",
    "        self.kit.servo[10].angle = self.pan\n",
    "        self.kit.servo[11].angle = self.tilt\n",
    "\n",
    "        # Camera setup\n",
    "        self.picamera = Picamera2()\n",
    "        config = self.picamera.create_preview_configuration(main={\"format\": 'XRGB8888', \"size\": (640, 480)})\n",
    "        config[\"transform\"] = libcamera.Transform(hflip=0, vflip=1)\n",
    "        self.picamera.configure(config)\n",
    "        self.picamera.start()\n",
    "\n",
    "        # Face Tracking Parameter\n",
    "        self.dispW = 640\n",
    "        self.dispH = 480\n",
    "        self.face_cascade = cv2.CascadeClassifier('./images/haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # MediaPipe face mesh\n",
    "        self.detector = self.initialize_face_landmarker()\n",
    "\n",
    "        # Drawing utils\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "        # FPS tracking\n",
    "        self.COUNTER = 0\n",
    "        self.FPS = 0\n",
    "        self.START_TIME = time.time()\n",
    "        self.DETECTION_RESULT = None\n",
    "        self.fps_avg_frame_count = 10\n",
    "\n",
    "        # Data collection\n",
    "        self.blendshape_data = []  # 用于存储每秒的平均值\n",
    "        self.current_blendshapes = defaultdict(list)  # 用于累积每帧的分数\n",
    "        self.last_log_time = time.time()  # 上次记录的时间\n",
    "\n",
    "    def initialize_face_landmarker(self):\n",
    "        base_options = python.BaseOptions(model_asset_path='face_landmarker.task')\n",
    "        options = vision.FaceLandmarkerOptions(\n",
    "            base_options=base_options,\n",
    "            running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "            num_faces=2,\n",
    "            min_face_detection_confidence=0.5,\n",
    "            min_face_presence_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            output_face_blendshapes=True,\n",
    "            result_callback=self.save_result)\n",
    "        return vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "    def save_result(self, result: vision.FaceLandmarkerResult, unused_output_image: mp.Image, timestamp_ms: int):\n",
    "        if self.COUNTER % self.fps_avg_frame_count == 0:\n",
    "            self.FPS = self.fps_avg_frame_count / (time.time() - self.START_TIME)\n",
    "            self.START_TIME = time.time()\n",
    "        self.DETECTION_RESULT = result\n",
    "        self.COUNTER += 1\n",
    "\n",
    "    def bgr8_to_jpeg(self, value, quality=75):\n",
    "        return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "    def update_servo(self, x, y, w, h):\n",
    "        Xcent = x + w / 2\n",
    "        Ycent = y + h / 2\n",
    "        errorPan = Xcent - self.dispW / 2\n",
    "        errorTilt = Ycent - self.dispH / 2\n",
    "        if abs(errorPan) > 15:\n",
    "            self.pan -= errorPan / 40\n",
    "        if abs(errorTilt) > 15:\n",
    "            self.tilt -= errorTilt / 40\n",
    "        self.pan = max(0, min(180, self.pan))\n",
    "        self.tilt = max(0, min(180, self.tilt))\n",
    "        self.kit.servo[10].angle = 180 - self.pan\n",
    "        self.kit.servo[11].angle = 180 - self.tilt\n",
    "\n",
    "    def draw_blendshapes(self, frame):\n",
    "        if not self.DETECTION_RESULT:\n",
    "            return frame\n",
    "        \n",
    "        label_padding_width = 1500\n",
    "        label_background_color = (255, 255, 255)       \n",
    "        frame = cv2.copyMakeBorder(frame, 0, 0, 0, label_padding_width, cv2.BORDER_CONSTANT, None, label_background_color)\n",
    "\n",
    "        legend_x = frame.shape[1] - label_padding_width + 20\n",
    "        legend_y = 30\n",
    "        bar_max_width = label_padding_width - 40\n",
    "        bar_height = 8\n",
    "        gap_between_bars = 5\n",
    "        text_gap = 5\n",
    "\n",
    "        face_blendshapes = self.DETECTION_RESULT.face_blendshapes\n",
    "        \n",
    "        if face_blendshapes:\n",
    "            for idx, category in enumerate(face_blendshapes[0]):\n",
    "                category_name = category.category_name\n",
    "                score = round(category.score, 2)\n",
    "                text = f\"{category_name} ({score:.2f})\"\n",
    "                # Accumulate data\n",
    "                self.current_blendshapes[category_name].append(score)\n",
    "                (text_width, _), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "                cv2.putText(frame, text, (legend_x, legend_y + bar_height // 2 + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                bar_width = int(bar_max_width * score)\n",
    "                cv2.rectangle(frame, (legend_x + text_width + text_gap, legend_y),\n",
    "                              (legend_x + text_width + text_gap + bar_width, legend_y + bar_height),\n",
    "                              (0, 255, 0), -1)\n",
    "                legend_y += (bar_height + gap_between_bars)\n",
    "        return frame\n",
    "\n",
    "    def draw_landmarks(self, frame):\n",
    "        if not self.DETECTION_RESULT:\n",
    "            return\n",
    "        for face_landmarks in self.DETECTION_RESULT.face_landmarks:\n",
    "            face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            face_landmarks_proto.landmark.extend([\n",
    "                landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z)\n",
    "                for landmark in face_landmarks\n",
    "            ])\n",
    "            self.mp_drawing.draw_landmarks(\n",
    "                image=frame,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=self.mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            self.mp_drawing.draw_landmarks(\n",
    "                image=frame,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=self.mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "            self.mp_drawing.draw_landmarks(\n",
    "                image=frame,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=self.mp_face_mesh.FACEMESH_IRISES,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "            \n",
    "    def log_blendshapes(self, log_time):\n",
    "            if not self.current_blendshapes:\n",
    "                return\n",
    "\n",
    "            # 计算每个 category_name 的平均分数\n",
    "            averaged_blendshapes = {\n",
    "                category_name: sum(scores) / len(scores)\n",
    "                for category_name, scores in self.current_blendshapes.items()\n",
    "            }\n",
    "\n",
    "            # 将结果存储到 blendshape_data 中\n",
    "            for category_name, avg_score in averaged_blendshapes.items():\n",
    "                self.blendshape_data.append({\n",
    "                    'Time': log_time,\n",
    "                    'Category': category_name,\n",
    "                    'Average Score': round(avg_score, 2)\n",
    "                })\n",
    "\n",
    "            # 清空当前累积数据\n",
    "            self.current_blendshapes.clear()\n",
    "\n",
    "    def save_blendshapes(self, file_path):\n",
    "        df = pd.DataFrame(self.blendshape_data)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Blendshapes data saved to {file_path}\")\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            frame = self.picamera.capture_array()\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.flip(frame, 1)\n",
    "            image = image.astype(np.uint8)\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            raw_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)  # 强制格式为BGR\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "\n",
    "            self.detector.detect_async(mp_image, time.time_ns() // 1_000_000)\n",
    "\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                self.update_servo(x, y, w, h)\n",
    "\n",
    "            fps_text = f'FPS = {self.FPS:.1f}'\n",
    "            cv2.putText(raw_image, fps_text, (24, 50), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            self.draw_landmarks(raw_image)\n",
    "            raw_image = self.draw_blendshapes(raw_image)\n",
    "            self.face_image_widget.value = self.bgr8_to_jpeg(raw_image)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if current_time - self.last_log_time >= 1.0:\n",
    "                log_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "                self.log_blendshapes(log_time)\n",
    "                self.last_log_time = current_time\n",
    "\n",
    "\n",
    "# 示例：运行\n",
    "if __name__ == \"__main__\":\n",
    "    monitor = DriverMonitor()\n",
    "    try: \n",
    "        monitor.run()\n",
    "    except KeyboardInterrupt:\n",
    "        monitor.save_blendshapes(\"data/Camera.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
